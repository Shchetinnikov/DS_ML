{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7dba604",
   "metadata": {},
   "source": [
    "# Логистическая регрессия\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da418cd",
   "metadata": {},
   "source": [
    "### *1)Теория*\n",
    "\n",
    "Для начала поговорим о *контролируемом обучении*.\n",
    "\n",
    "**Контролируемое обучение** – это обучение, где у вас есть входные переменные (х) и выходная переменная (Y) и вы используете алгоритм, чтобы узнать функцию отображения от входа к выходу.\n",
    "y = f (X)\n",
    "\n",
    "Намерение состоит в том, чтобы обучить функцию так, чтобы всякий раз, когда у нас были какие-либо новые входные данные (x), вы могли легко предсказать выходные переменные (Y) для этого заданного набора входных данных.\n",
    "Таким образом, здесь обучение проходит под наблюдением учителя/помощника, который уже знает правильные ответы, а алгоритм итеративно делает прогнозы по данным обучения и корректируется супервизором. \n",
    "\n",
    "Одними из задач контролируемого машинного обучения является регрессия и классификация.\n",
    "\n",
    "**Задачи регрессии** - это задачи, в которых мы пытаемся сделать прогноз в непрерывном масштабе. Примерами могут быть прогнозирование цены акций компании или прогнозирование температуры на основе исторических данных. \n",
    "\n",
    "В отличие от обычной регрессии, в методе логистической регрессии не производится предсказание значения числовой переменной исходя из выборки исходных значений. Вместо этого, значением функции является вероятность того, что данное исходное значение принадлежит к определенному классу. Для простоты, давайте предположим, что у нас есть только два класса.\n",
    "\n",
    "Основная идея логистической регрессии заключается в том, что пространство исходных значений может быть разделено линейной границей (т.е. прямой) на две соответствующих классам области. Итак, что же имеется в виду под линейной границей? В случае двух измерений — это просто прямая линия без изгибов. В случае трех — плоскость, и так далее. Эта граница задается в зависимости от имеющихся исходных данных и обучающего алгоритма. Чтобы все работало, точки исходных данных должны разделяться линейной границей на две вышеупомянутых области. Если точки исходных данных удовлетворяют этому требованию, то их можно назвать линейно разделяемыми.\n",
    "\n",
    "Применять классификацию можно во многих областях науки и техники. Например, алгоритмы классификации текста используются для разделения легитимных писем и спама, а также положительных и отрицательных комментариев. Другие примеры включают медицинские приложения, биологическую классификацию, кредитный рейтинг и многое другое. Задачи распознавания изображений часто представляют как задачи классификации.\n",
    "\n",
    "### *2) Понятие логистической регрессии*\n",
    "\n",
    "Для лучшего понимания приведём несколько определений:\n",
    "\n",
    "**Логистическая регрессия** (логит-модель) — статистическая модель, используемая для прогнозирования вероятности возникновения некоторого события путём его сравнения с логистической кривой. Эта регрессия выдаёт ответ в виде вероятности бинарного события (1 или 0).\n",
    "\n",
    "**Логистическая кривая** – график логистической функции:\n",
    "\n",
    "<img src=\"Image1.png\">\n",
    "\n",
    "**Логистическая регрессия** - это статистический метод для анализа набора данных, в котором есть одна или несколько независимых переменных, которые определяют результат. Результат измеряется с помощью дихотомической переменной (в которой есть только два возможных результата). Он используется для прогнозирования двоичного результата (1/0, Да / Нет, Истина / Ложь) с учетом набора независимых переменных.\n",
    "\n",
    "Также можно рассматривать логистическую регрессию как особый случай линейной регрессии, когда исходная переменная является категориальной, где мы используем логарифм шансов в качестве зависимой переменной. Проще говоря, он предсказывает вероятность возникновения события путем подгонки данных к logit функции.\n",
    "\n",
    "### *3) Математика*\n",
    "\n",
    "Логистическая регрессия — это линейный классификатор, поэтому вы будете использовать линейную функцию также называемую logit <img src=\"Image2.png\">\n",
    "\n",
    "Переменные <img src=\"Image3.png\"> являются оценками коэффициентов регрессии, которые также называются прогнозируемыми весами или просто коэффициентами. Функция логистической регрессии p(x) является сигмоидой f(x). <img src=\"Image4.png\">\n",
    "\n",
    "\n",
    "Функция p(x) часто интерпретируется как прогнозируемая вероятность того, что выход для данного равен 1. Следовательно, 1 - p(x) — это вероятность того, что выход равен 0.\n",
    "\n",
    "Логистическая регрессия определяет наилучшие предсказанные веса так, чтобы функция p(x) была как можно ближе ко всем фактическим ответам y из наблюдений. Процесс вычисления лучших весов с использованием имеющихся наблюдений называется обучением модели или подгонкой.\n",
    "\n",
    "После определения наилучших весов, которые определяют функцию p(x), вы можете получить прогнозируемые выходные данные p(xi) для любого заданного входа xi. Для каждого наблюдения прогнозируемый результат равен 1, если p(xi) > 0,5p и 0 в противном случае.\n",
    "\n",
    "Порог не обязательно должен быть 0,5, но обычно это так. Вы можете определить более низкое или более высокое значение, если это более удобно для вашей ситуации.\n",
    "\n",
    "Есть еще одно важное соотношение между p(x) и f(x): <img src=\"Image5.png\">\n",
    "\n",
    "Это равенство объясняет, почему f(x) является logit.\n",
    "\n",
    "Чтобы получить лучший вес, обычно максимизируют функцию логарифма правдоподобия (LLF) для всех наблюдений. Этот метод называется оценкой максимального правдоподобия и представляется уравнением <img src=\"Image6.png\">\n",
    "\n",
    "### *4) Эффективность классификации*\n",
    "\n",
    "Бинарная классификация имеет четыре возможных типа результатов:\n",
    "\n",
    "**Истинно отрицательные**: правильно предсказанные негативы (нули) \\\n",
    "**Истинно положительные**: правильно предсказанные положительные (единицы) \\\n",
    "**Ложно отрицательные**: неверно предсказанные отрицания (нули)\\\n",
    "**Ложно положительные**: неверно предсказанные срабатывания (единицы).\n",
    "\n",
    "Обычно точность классификатора оценивается, сравнивая фактические и прогнозируемые результаты и подсчитывая правильные и неправильные прогнозы.\n",
    "\n",
    "Самый простой индикатор точности классификации — это отношение количества правильных предсказаний к общему количеству предсказаний (или наблюдений). \n",
    "\n",
    "Другие индикаторы бинарных классификаторов включают следующее:\n",
    "\n",
    "**Прогнозирующая ценность положительного результата** — это отношение количества истинных положительных результатов к сумме количества истинных и ложных положительных результатов.\\\n",
    "**Прогнозирующая ценность отрицательного результата** — это отношение количества истинно отрицательных результатов к сумме количества истинных и ложных отрицаний.\\\n",
    "**Чувствительность** (также известная как отзыв или истинно положительный результат) — это отношение количества истинных положительных результатов к количеству фактических положительных результатов.\\\n",
    "**Специфичность** (или истинно отрицательный показатель) — это отношение количества истинных негативов к количеству реальных негативов.\n",
    "\n",
    "### *5) Регулязация*\n",
    "\n",
    "Переобучение — одна из самых серьезных проблем, связанных с машинным обучением. Переобученные модели, как правило, имеют хорошую точность с данными, используемыми для их соответствия (данные обучения), но они плохо себя ведут с невидимыми данными (или тестовыми данными, которые не используются для соответствия модели). Переобучение обычно происходит со сложными моделями. Регуляризация обычно пытается уменьшить сложность модели или снизить ее. \n",
    "\n",
    "Методы регуляризации, применяемые с логистической регрессией, в основном имеют тенденцию штрафовать за большие коэффициенты (к примеру штрафование LLF).\n",
    "Регуляризация может значительно улучшить точность модели для невидимых данных.\n",
    "\n",
    "### *6) Примеры использования логистической регрессии в Python*\n",
    "\n",
    "Предлагаю рассмотреть два способа решения. Один с ипользованием математических формул, другой с использованием библиотек.\n",
    " \n",
    "\n",
    "#### **1) Набор данных диабета индейцев пима и  стохастический градиентный спуск**\n",
    "\n",
    "В этой задаче рассмотрим прогнозирование диабета в течение 5 лет у индейцев пима с учетом основных медицинских данных.\n",
    "\n",
    "Это проблема бинарной классификации, где прогноз - 0 (нет диабета) или 1 (диабет).\n",
    "\n",
    "И первым нашим шагом будет объявление необходимых нам библиотек:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "aa8b12f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange\n",
    "from csv import reader\n",
    "from math import exp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68efd226",
   "metadata": {},
   "source": [
    "Ниже представленна формула для расчёта логит функции:\n",
    "\n",
    "yhat = 1.0 / (1.0 + e^(-(b0 + b1 * x1)))\n",
    "\n",
    "Реализуюм ее в коде:\\\n",
    "(row: Независимые переменные \\\n",
    "coefficients: Известные на данный момент весы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "4d9e1722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(row, coefficients):\n",
    "\tz = coefficients[0]\n",
    "\tfor i in range(len(row)-1):\n",
    "\t\tz += coefficients[i + 1] * row[i]\n",
    "\treturn 1.0 / (1.0 + exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e2516e",
   "metadata": {},
   "source": [
    "Для подсчета лучших весов будем использовать *стохастический градиентный спуск* (извините, но нужно пояснить еще немного математики, ноо чуть-чуть)\n",
    "\n",
    "**Градиентный спуск** - это процесс минимизации функции, следуя градиентам функции стоимости.\n",
    "\n",
    "Стохастический градиентный спуск заменяет реальный градиент, вычисленный из полного набора данных его оценкой, вычисленной из случайно выбранного подмножества данных. Это сокращает задействованные вычислительные ресурсы и помогает достичь более высокой скорости итераций в обмен на более низкую скорость сходимости.Особенно большой эффект достигается в приложениях связанных с обработкой больших данных.\n",
    "\n",
    "Этот алгоритм оптимизации работает так, что каждый обучающий экземпляр показывается модели по одному. Модель делает прогноз для обучающего экземпляра, вычисляется ошибка, и модель обновляется, чтобы уменьшить ошибку для следующего прогнозирования.\n",
    "\n",
    "Эта процедура может использоваться для нахождения лучших весов. На каждой итерации коэффициенты (b) в языке машинного обучения обновляются с использованием уравнения:\n",
    "\n",
    "**b1(t+1) = b1(t) + learning_rate * (y(t) - yhat(t)) * yhat(t) * (1 - yhat(t)) * x1(t)**\n",
    "\n",
    "b - это i-ый вес, \\\n",
    "learning_rate - скорость обучения, которую вы должны настроить (например, 0,01), \\\n",
    "(y(i) - yhat(i)) - ошибка прогноза для модели на тренировочных данных, отнесенных к весу, \\\n",
    "yhat(i) - прогноз, сделанный коэффициентами известныим до этого и x1(i) - это входные данные.\n",
    "\n",
    "Специальный коэффициент в начале списка, также называемый перехватом, обновляется аналогичным образом, за исключением того, что он не связан с конкретным входным значением:\n",
    "\n",
    "**b0(t+1) = b0(t) + learning_rate * (y(t) - yhat(t)) * yhat(t) * (1 - yhat(t))**\n",
    "\n",
    "Реализация в коде: \\\n",
    "(train: Тренировочные данные \\\n",
    "l_rate: Используется для ограничения суммы, каждый коэффициент корректируется при каждом обновлении. \\\n",
    "n_epoch: Количество раз, которое нужно пройти через данные обучения при обновлении коэффициентов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "3bd9b1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coefficients_sgd(train, l_rate, n_epoch):\n",
    "\tcoef = [0.0 for i in range(len(train[0]))]\n",
    "\tfor epoch in range(n_epoch):\n",
    "\t\tsum_error = 0\n",
    "\t\tfor row in train:\n",
    "\t\t\tyhat = predict(row, coef)\n",
    "\t\t\terror = row[-1] - yhat\n",
    "\t\t\tsum_error += error**2\n",
    "\t\t\tcoef[0] = coef[0] + l_rate * error * yhat * (1.0 - yhat)\n",
    "\t\t\tfor i in range(len(row)-1):\n",
    "\t\t\t\tcoef[i + 1] = coef[i + 1] + l_rate * error * yhat * (1.0 - yhat) * row[i]\n",
    "        #Можно использовать, чтобы проследить как меняется ошибка каждую эпоху\n",
    "\t\t#print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))  \n",
    "\treturn coef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1c467f",
   "metadata": {},
   "source": [
    "Теперь нужно определить откуда мы возьмем данные для обучения и теста и как их будем передавать. Сперва разберемся откуда.\n",
    "\n",
    "Сначала загружается набор данных (набор данных в формате CSV находится в текущем рабочем каталоге с именем файла **pima-indians-diabetes.csv**). Строковые значения преобразуются в числовые, и каждый столбец нормализуется до значений в диапазоне от 0 до 1. Это достигается с помощью вспомогательных функций: ***load_csv()*** , а также ***str_column_to_float()***.\n",
    "Загрузика и подготовка набора данных реализуется через ***dataset_minmax()*** и ***normalize_dataset()***.\n",
    "\n",
    "Мы будем использовать перекрестную проверку в k-кратном размере для оценки эффективности изученной модели на невидимых данных. Это означает, что мы будем строить и оценивать k моделей и оценивать производительность как среднюю производительность модели. Точность классификации будет использоваться для оценки каждой модели. Эти поведения представлены в ***cross_validation_split()***, ***accuracy_metric()***, а также ***evaluate_algorithm()*** ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "24216f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем CSV файл\n",
    "def load_csv(filename):\n",
    "\tdataset = list()\n",
    "\twith open(filename, 'r') as file:\n",
    "\t\tcsv_reader = reader(file)\n",
    "\t\tfor row in csv_reader:\n",
    "\t\t\tif not row:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tdataset.append(row)\n",
    "\treturn dataset\n",
    "\n",
    "# Конвертирует строчки из колонок в вещественные числа\n",
    "def str_column_to_float(dataset, column):\n",
    "\tfor row in dataset:\n",
    "\t\trow[column] = float(row[column].strip())\n",
    "\n",
    "# Находит минимальные и максимальные значения для каждой колонки\n",
    "def dataset_minmax(dataset):\n",
    "\tminmax = list()\n",
    "\tfor i in range(len(dataset[0])):\n",
    "\t\tcol_values = [row[i] for row in dataset]\n",
    "\t\tvalue_min = min(col_values)\n",
    "\t\tvalue_max = max(col_values)\n",
    "\t\tminmax.append([value_min, value_max])\n",
    "\treturn minmax\n",
    "\n",
    "# Изменяет значение столбцов набора данных до диапазона 0–1 \n",
    "def normalize_dataset(dataset, minmax):\n",
    "\tfor row in dataset:\n",
    "\t\tfor i in range(len(row)):\n",
    "\t\t\trow[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
    "\n",
    "# Разделяет набор данных на k моделей\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "\tdataset_split = list()\n",
    "\tdataset_copy = list(dataset)\n",
    "\tfold_size = int(len(dataset) / n_folds)\n",
    "\tfor i in range(n_folds):\n",
    "\t\tfold = list()\n",
    "\t\twhile len(fold) < fold_size:\n",
    "\t\t\tindex = randrange(len(dataset_copy))\n",
    "\t\t\tfold.append(dataset_copy.pop(index))\n",
    "\t\tdataset_split.append(fold)\n",
    "\treturn dataset_split\n",
    "\n",
    "# Рассчитывает процент точности \n",
    "def accuracy_metric(actual, predicted):\n",
    "\tcorrect = 0\n",
    "\tfor i in range(len(actual)):\n",
    "\t\tif actual[i] == predicted[i]:\n",
    "\t\t\tcorrect += 1\n",
    "\treturn correct / float(len(actual)) * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba16e7ca",
   "metadata": {},
   "source": [
    "Осталось понять, куда мы передаем данные, чтобы расчитать результат работы данного метода реализации логистической регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "7cc88820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "\tfolds = cross_validation_split(dataset, n_folds)\n",
    "\tscores = list()\n",
    "\tfor fold in folds:\n",
    "\t\ttrain_set = list(folds)\n",
    "\t\ttrain_set.remove(fold)\n",
    "\t\ttrain_set = sum(train_set, [])\n",
    "\t\ttest_set = list()\n",
    "\t\tfor row in fold:\n",
    "\t\t\trow_copy = list(row)\n",
    "\t\t\ttest_set.append(row_copy)\n",
    "\t\t\trow_copy[-1] = None\n",
    "\t\tpredicted = algorithm(train_set, test_set, *args)\n",
    "\t\tactual = [row[-1] for row in fold]\n",
    "\t\taccuracy = accuracy_metric(actual, predicted)\n",
    "\t\tscores.append(accuracy)\n",
    "\treturn scores\n",
    "\n",
    "def logistic_regression(train, test, l_rate, n_epoch):\n",
    "\tpredictions = list()\n",
    "\tcoef = coefficients_sgd(train, l_rate, n_epoch)\n",
    "\tfor row in test:\n",
    "\t\tyhat = predict(row, coef)\n",
    "\t\tyhat = round(yhat)\n",
    "\t\tpredictions.append(yhat)\n",
    "\treturn(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a460059",
   "metadata": {},
   "source": [
    "Осталось всего несколько строчек, чтобы запустить наш метод и просмотреть результаты его работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "2e3c9e37",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [77.77777777777779, 80.3921568627451, 67.97385620915033, 80.3921568627451, 77.12418300653596]\n",
      "Mean Accuracy: 76.732%\n",
      "Scores: [59.47712418300654, 60.78431372549019, 64.70588235294117, 67.97385620915033, 71.89542483660131]\n",
      "Mean Accuracy: 64.967%\n",
      "Scores: [75.16339869281046, 81.69934640522875, 73.20261437908496, 73.8562091503268, 77.77777777777779]\n",
      "Mean Accuracy: 76.340%\n",
      "Scores: [75.16339869281046, 77.77777777777779, 79.08496732026144, 74.50980392156863, 77.77777777777779]\n",
      "Mean Accuracy: 76.863%\n"
     ]
    }
   ],
   "source": [
    "# Загрузка и подготовка данных\n",
    "filename = 'pima-indians-diabetes.csv'\n",
    "dataset = load_csv(filename)\n",
    "for i in range(len(dataset[0])):\n",
    "\tstr_column_to_float(dataset, i)\n",
    "    \n",
    "# нормализация\n",
    "minmax = dataset_minmax(dataset)\n",
    "normalize_dataset(dataset, minmax)\n",
    "\n",
    "n_folds = 5\n",
    "l_rate = 0.1\n",
    "n_epoch = 100\n",
    "scores = evaluate_algorithm(dataset, logistic_regression, n_folds, l_rate, n_epoch)\n",
    "print('Scores: %s' % scores)\n",
    "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))\n",
    "\n",
    "n_folds = 5\n",
    "l_rate = 0.0001\n",
    "n_epoch = 100\n",
    "scores = evaluate_algorithm(dataset, logistic_regression, n_folds, l_rate, n_epoch)\n",
    "print('Scores: %s' % scores)\n",
    "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))\n",
    "\n",
    "n_folds = 5\n",
    "l_rate = 0.1\n",
    "n_epoch = 50\n",
    "scores = evaluate_algorithm(dataset, logistic_regression, n_folds, l_rate, n_epoch)\n",
    "print('Scores: %s' % scores)\n",
    "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))\n",
    "\n",
    "n_folds = 5\n",
    "l_rate = 0.1\n",
    "n_epoch = 150\n",
    "scores = evaluate_algorithm(dataset, logistic_regression, n_folds, l_rate, n_epoch)\n",
    "print('Scores: %s' % scores)\n",
    "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce625c10",
   "metadata": {},
   "source": [
    "Выполнение этого примера печатает оценки для каждого из 5 сгибов перекрестной проверки, а затем печатает среднюю точность классификации.\n",
    "\n",
    "Выше приведены несколько примеров с разными значениями l_rate и  n_epoch. \n",
    "\n",
    "Можно заметить, что с разной комбинацией этих величин можно получить разную точность предсказаний."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a0409f",
   "metadata": {},
   "source": [
    "#### **2) Реализация через библиотеки**\n",
    "\n",
    "Ну и начальным нашим шагом конечно будет обьевление библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114f1eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6160d3e",
   "metadata": {},
   "source": [
    "Расмотрим, как использовать библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e58849",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier = LogisticRegression(solver='sag',random_state=0)\n",
    "#classifier.fit(x_train, y_train)\n",
    "#print('Accuracy: {:.2f}'.format(classifier.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5245355",
   "metadata": {},
   "source": [
    "При их использовании независимые и зависимые переменные нужно подавать в разных списках. Кроме того стоит отметить, что функция LogisticRegression имеет много параметров. \n",
    "\n",
    "Теперь посмотрим, как выглядит прогнозирование диабета индейцев пима с нашим новым методом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "67b2f03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.79\n"
     ]
    }
   ],
   "source": [
    "filename = 'pima-indians-diabetes.csv'\n",
    "dataset = load_csv(filename)\n",
    "for i in range(len(dataset[0])):\n",
    "\tstr_column_to_float(dataset, i)\n",
    "    \n",
    "minmax = dataset_minmax(dataset)\n",
    "normalize_dataset(dataset, minmax)\n",
    "\n",
    "folds = cross_validation_split(dataset, 2)\n",
    "for fold in folds:\n",
    "    train_set = list(folds)\n",
    "    train_set.remove(fold)\n",
    "    train_set = sum(train_set, [])\n",
    "    test_set = list()\n",
    "    for row in fold:\n",
    "        row_copy = list(row)\n",
    "        test_set.append(row_copy)\n",
    "        \n",
    "        \n",
    "    x_train = list()\n",
    "    y_train = list()\n",
    "    for i in range(len(train_set)):\n",
    "        if (len(train_set[i]) == 9):\n",
    "            x_train.append(train_set[i])\n",
    "            y_train.append(train_set[i][-1])\n",
    "            del(x_train[i][-1])\n",
    "    \n",
    "    x_test = list()\n",
    "    y_test = list()\n",
    "    for i in range(len(test_set)):\n",
    "        if (len(test_set[i]) == 9):\n",
    "            x_test.append(test_set[i])\n",
    "            y_test.append(test_set[i][-1])\n",
    "            del(x_test[i][-1])\n",
    "            \n",
    "    \n",
    "    if (len(x_test) != 0):\n",
    "    \n",
    "        classifier = LogisticRegression(solver='sag',random_state=0)\n",
    "        classifier.fit(x_train, y_train)\n",
    "        print('Accuracy: {:.2f}'.format(classifier.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb59f160",
   "metadata": {},
   "source": [
    "Да реализовано не без костылей, но сейчас главное было показать, как работает логистическая регрессия из библиотек.\n",
    "\n",
    "И работает это довольно просто. У логистической регрессии из библиотек довольно высокая точность и есть не мало настроек, поэтому достижение максимальной точности достигается через правильную обработку входных данных."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
